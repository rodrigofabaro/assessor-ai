# Assessor-AI â€” Milestones

This is the â€œboring but reliableâ€ build tracker.
Rule: each milestone ends with a working UI path + DB truth + audit trail.

---

## âœ… M1 â€” Upload & Tracking Engine (DONE)
**Outcome**
- Upload single + batch submissions (PDF/DOCX)
- Store files on disk + DB record per submission
- Submission list UI + status tracking

**Acceptance**
- Uploads create DB rows
- Files persist and can be re-opened
- Status transitions are consistent and visible

---

## âœ… M2 â€” Reference Library (Specs/Briefs) (DONE / PARTIAL if still iterating)
**Outcome**
- Admin upload reference docs (unit specs, briefs)
- Parse + store structured reference data
- Bind assignments â†’ criteria universe

**Acceptance**
- Reference docs stored and re-usable
- Assignment â€œbindingâ€ exists and is queryable
- No student grading yet

---

## ğŸŸ¨ M3 â€” Extraction Engine (IN PROGRESS)
**Outcome**
- Extract text from PDF/DOCX
- Per-page extraction stored separately from raw file
- Preview UI shows pages + extracted text
- Confidence/meaningful-text guards prevent nonsense

**Acceptance**
- Submission detail page shows:
  - original preview (left)
  - extracted text (right)
  - page navigation stable (no phantom pages)
- DB stores extraction output:
  - page index
  - text
  - method (pdf-text / docx / vision-later)
  - confidence + flags

---

## ğŸ”œ M4 â€” Student Detail Page (Teacher Tool Feel)
**Outcome**
- `/students/[id]` becomes the main operational cockpit
- Shows student identity + their submission history + latest outcomes
- No duplication: uses existing submissions table and joins

**Acceptance**
- A student page loads instantly and shows:
  - student profile basics
  - timeline/table of all submissions (most recent first)
  - quick filters: assignment / status / date
  - click-through into `/submissions/[submissionId]`

---

## ğŸ”œ M5 â€” Grading Engine v1 (Explainable JSON)
**Outcome**
- Strict per-criterion decisions with evidence pointers
- Overall grade calculated from criteria
- Human-tone feedback generated from the structured decisions

**Acceptance**
- Given a submission + its bound criteria:
  - produces structured JSON
  - stores model + prompt version
  - stores evidence mapping to extracted text regions/pages

---

## ğŸ”œ M6 â€” Marked PDF Generator
**Outcome**
- Annotated PDF: highlights/ticks/comments linked to criteria
- Original layout preserved

**Acceptance**
- Downloadable marked PDF attached to submission record
- Annotation log stored for audit

---

## ğŸ”œ M7 â€” Export Packs (Downstream Friendly)
**Outcome**
- One-click export:
  - authoritative JSON
  - marked PDF
  - optional CSV summary (batch)
  - optional ZIP pack

**Acceptance**
- Export is deterministic and repeatable
- Past exports can be regenerated identically (versioned prompts/models logged)

---

## Notes / Principles
- No grading without reliable extraction.
- Store everything needed to defend a grade.
- Prefer â€œpredictable and boringâ€ over â€œclever and fragileâ€.
